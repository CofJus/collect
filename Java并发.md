## 1 Java线程模型

### 1.1 Java线程状态转换

![](https://cdn.tobebetterjavaer.com/stutymore/thread-state-and-method-20230829143200.png)

### 1.2 阻塞、等待、超时等待的区别

|          | BLOCKED（阻塞）                     | WAITING（等待）           | TIMED_WAITING（超时等待）               |
| -------- | ----------------------------------- | ------------------------- | --------------------------------------- |
| 进入原因 | 竞争资源（**锁**）或I/O（文件读写） | 主动放弃CPU资源           | 主动放弃CPU资源 **并设置超时时间**      |
| 转变原因 | 被竞争资源的资源得到释放            | 需要其他线程唤醒          | 需要其他线程唤醒/**等待超时后自动唤醒** |
| 关键字   | synchronized/lock..                 | wait/notify,park/unpark.. | sleep,wait(long)/notify,parkNanos..     |

### 1.3 sleep和wait的区别

- 定义位置不同：sleep是Thread方法，wait是Object方法；

- 调用地方不同：sleep方法可以在任何地方使用；wait方法则只能和synchronized一起使用；

- 锁资源释放方式不同：sleep方法只让出了CPU，不释放锁； wait方法让出锁，只有调用了`notify`方法，之前调用wait的线程才会解除wait状态，可以去参与竞争同步资源锁；

- 异常捕获：sleep需要捕获或者抛出异常，而wait/notify/notifyAll则不需要；

### 1.4 Java线程和操作系统线程的关系

Java 线程状态是在操作系统线程状态的基础上进行的抽象和封装。Java 线程的运行最终还是要依赖操作系统的线程调度和执行机制。

Java线程模型简化了操作系统的线程模型。

Java中的线程和操作系统的线程并非一一对应，JVM可以将多个Java线程的任务分配给一个操作系统线程。

### 1.5 并行 并发

### 1.6 进程 线程 协程

## 2 Java内存模型（JMM）

JMM（Java Memory Model）主要聚焦于多线程环境下的内存访问规则，是对 JVM 内存管理的一种抽象和规范补充。

它涵盖的主题包括变量的可见性、指令重排、原子操作等，旨在解决由于多线程并发编程带来的一些问题。

### 2.1 happens-before原则

面向开发者而非编译器，happens-before在多线程程序的时间轴上建立了一个先后顺序的约束。

指令重排必须遵守这些规则。

- 程序顺序规则：代码顺序执行，前面的代码 happens-before后面的代码

- 管程锁定规则：加锁 happens-before 解锁 （monitorenter happens-before monitorexit）
- volatile变量规则：写happens-before读
- 线程启动规则：start方法happens-before其他任何操作
- 传递性规则：顾名思义

### 2.2 工作内存

JMM则规定，在线程共享的主内存之外，每个线程持有一块私有的工作内存。

主内存负责存储对象实例、静态变量等数据，而线程对变量的操作（如读取、赋值等）都在自己的工作内存中进行。

JMM 中的主内存概念可以对应到 JVM 中的堆、方法区等共享内存区域，线程的工作内存则可以看作是线程栈以及部分缓存机制（如 CPU 缓存）的抽象结合。

Java 内存模型定义了包括read、write、lock、unlock、load、store等8种同步操作，来保证工作内存和主内存的正确交互。

### 2.3 JMM和JVM运行时内存区域

简而言之，一个抽象，一个具体。

JMM针对的是多线程环境下，如何在主内存与工作内存之间安全地执行操作。它是一种规范，一个模型。

JVM运行时内存区域则是具体详细的内存划分，比如堆、栈、方法区等等。

JMM 定义的规则需要通过 JVM 来具体实现。JVM 在实现过程中会利用硬件的内存架构和自身的内存管理机制来满足 JMM 的要求。

## 3 volatile

volatile是Java对内存屏障的实现，保证变量的可见性和禁止指令重排序

### 3.1 可见性

可见性是指当一个线程修改了共享变量的值后，其他线程能够立即察觉到这个修改并获取到最新的值。

**破坏可见性**

- 缓存：计算机多级缓存
- 指令重排：多线程环境下，重排序可能会导致一个线程看到的共享变量的状态不符合预期

### 3.2 重排序

**引申**：CPU缓存一致性协议MESI，通过广播失效来保证多CPU的缓存一致性。同时为了避免阻塞带来性能问题，将缓存失效异步处理。

- 编译器指令重排：编译器层面的优化，对没有依赖关系的代码进行重排
- CPU指令重排：CPU层面的优化，提高并行度
- 内存系统重排：写缓冲区和失效队列异步处理缓存失效，带来指令执行顺序和写入内存顺序不一致的问题

### 3.3 内存屏障

本质是CPU指令，作用有两个

- 顺序性：禁止屏障两侧，即屏障这条CPU指令两侧的指令重排
- 一致性：强制刷新内存和失效其他CPU的缓存

三个指令

- 读屏障（Load）：确保在该屏障之后的读操作能够看到屏障之前的所有写操作的结果。
- 写屏障（Store）：保证在该屏障之前的写操作先于屏障之后的写操作执行，并且将屏障之前的写操作的结果刷新到主内存中。
- 全屏障（Full）：同时保证读写操作的可见性和顺序性

组合出四种内存屏障：StoreStore,LoadLoad,LoadStore,StoreLoad

StoreLoad最通用，屏障左边的写操作会被立即刷入主存，屏障右边的读操作会从主存读最新的值。从而保证了可见性。

### 3.4 volatile实现

对于被volatile修饰的变量

写操作之前：加StoreStore屏障，保证当前写操作一定是在之前的写操作生效的基础上进行的，保证两次写操作的顺序性。

写操作之后：加StoreLoad屏障，保证当前写操作产生的结果对之后的读操作可见。

读操作之前：加LoadLoad屏障，保证在当前读操作之前的读操作不会被重排到后面。

读操作之后：加LoadStore屏障，保证在读操作之后的写操作不会被重排到读操作之前。

### 3.5 volatile和原子性

volatile只作用于变量的单个读/写操作，对于复合操作如自增自减无能为力。

## 4 synchronized

### 4.1 Monitor锁对象

**Synchronized可以把任何一个非null对象作为"锁"**

作用方式不同时，Monitor对象也不同

- 同步代码块：锁住给定的对象
- 同步方法：锁对象实例this
- 同步静态方法：锁住class对象

### 4.2 同步原理

synchronized的同步依赖monitorenter和monitorexit两条指令实现，前者加锁，后者退出锁。

**两个指令的执行是JVM通过调用操作系统的互斥原语mutex来实现，被阻塞的线程会被挂起、等待重新调度**，会导致用户态和内核态两个态之间来回切换，对性能有较大影响。

### 4.3 MESA管程模型

管程的主要目的是将共享资源的管理和对这些资源的操作封装在一起，使得对共享资源的访问能够以一种安全、有序的方式进行。在管程内部，有一套规则来确保在同一时刻只有一个线程能够访问共享资源。

Java的同步synchronized和AQS均基于MESA管程模型实现。

**共享变量封装：**在 MESA 管程模型中，共享变量被定义在管程内部，外部线程无法直接访问这些变量，只能通过管程提供的接口方法来操作。对于synchronized，共享变量就是Monitor锁对象，对外提供wait、notify等方法操作Monitor对象。

**入口队列：**当多个线程试图进入管程时，会在管程的入口处形成一个队列，称为入口队列。入口队列的存在确保了线程按照一定的顺序（通常是先来先服务，但也可以根据具体实现有所不同）进入管程。在Java中，同时只有一个对象能获取锁，被阻塞的线程类似于入口队列机制，在Monitor对象之外等待。

**条件变量和等待队列：**用于让线程在某个条件不满足时等待，直到其他线程使这个条件满足并唤醒等待的线程。每个条件变量都与一个等待队列相关联，线程可以在这个等待队列中等待特定条件的满足。用Java代入这个模型，wait释放当前锁进入等待状态，这个状态类似于进入等待队列。

### 4.4 锁优化

#### 4.4.1 自适应自旋锁

**线程的阻塞和唤醒需要CPU从用户态转为核心态**，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，**对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的**。所以引入自旋锁，当一个线程尝试获取某个锁时，**如果该锁已被其他线程占用，就一直循环检测锁是否被释放**，而不是进入线程挂起或睡眠状态。

自旋必须有一个限度，无限自旋是对CPU资源的浪费。

引入自适应自旋次数：自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多，反之减少。

#### 4.4.2 锁消除

有些情况下，JVM检测到不可能存在共享数据竞争（逃逸分析），这是JVM会对这些同步锁进行锁消除。

#### 4.4.3 锁粗化

如果对锁的使用过于精细，可能会导致性能下降。锁粗化就是将多个连续的、对同一个锁的操作合并为一个范围更大的锁操作，从而减少获取和释放锁的次数，以提高性能。

场景：循环加锁，JVM会把锁提到循环外。

#### 4.4.4 锁膨胀

无锁->偏向锁->轻量级锁->重量级锁

#### 4.4.5 偏向锁

**在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得。**引入偏向锁，降低线程加锁的代价。偏向锁非常适合在单线程环境下或者在多线程环境中，一个对象的同步块主要被一个线程频繁访问，而其他线程很少访问的情况。

**加锁：**检查Java对象头中Mark Word中的偏向锁标志位，若无偏向锁则写入当前的线程id从而获得锁；若有则检查当前的偏向锁线程id，相等则直接获取锁，不等则膨胀为轻量级锁。

**解锁：**同步代码块执行结束释放；当其他线程来竞争时，JVM在Safe Point暂停当前持有偏向锁的线程，然后根据这个线程同步代码执行状态决定是释放锁到无锁状态还是膨胀到轻量级锁；

#### 4.4.6 轻量级锁

**加锁：**膨胀为轻量级锁之后，JVM会先在当前线程的**栈桢**中创建**锁记录空间**，并将对象头中的Mark Word复制到锁记录中，然后线程尝试将对象头中的Mark Word的数据**CAS**为**指向锁记录的指针**。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在两条或两条以上的线程竞争同一个锁，则轻量级锁会膨胀成重量级锁。

**解锁：**尝试把栈帧锁空间中存储的Mark Word通过CAS放回对象头，成功则回归无锁状态或者再次偏向；失败则代表锁已被其他线程持有，不做任何操作。

#### 4.4.7 重量级锁

依赖于操作系统Mutex Lock实现，涉及线程的阻塞和唤醒，以及操作系统的调度，开销最大。

避免了自旋对CPU资源的消耗，适用于多线程竞争非常激烈，并且线程持有锁的时间较长的场景。

## 5 CAS

CAS和总线风暴

## 6 AQS

## 7 ReentrantLock

## 8 ReentrantReadWriteLock

## 9 Condition

## 10 LockSupport

## 11 并发容器

## 12 ThreadLocal

## 13 线程池

## 14 unsafe

## 15 ForkJoinPool





[☆啃碎并发（七）：深入分析Synchronized原理](https://www.jianshu.com/p/e62fa839aa41)