## 1 Java线程模型

### 1.1 Java线程状态转换

![](https://cdn.tobebetterjavaer.com/stutymore/thread-state-and-method-20230829143200.png)

### 1.2 阻塞、等待、超时等待的区别

|          | BLOCKED（阻塞）                     | WAITING（等待）           | TIMED_WAITING（超时等待）               |
| -------- | ----------------------------------- | ------------------------- | --------------------------------------- |
| 进入原因 | 竞争资源（**锁**）或I/O（文件读写） | 主动放弃CPU资源           | 主动放弃CPU资源 **并设置超时时间**      |
| 转变原因 | 被竞争资源的资源得到释放            | 需要其他线程唤醒          | 需要其他线程唤醒/**等待超时后自动唤醒** |
| 关键字   | synchronized/lock..                 | wait/notify,park/unpark.. | sleep,wait(long)/notify,parkNanos..     |

### 1.3 sleep和wait的区别

- 定义位置不同：sleep是Thread方法，wait是Object方法；

- 调用地方不同：sleep方法可以在任何地方使用；wait方法则只能和synchronized一起使用；

- 锁资源释放方式不同：sleep方法只让出了CPU，不释放锁； wait方法让出锁，只有调用了`notify`方法，之前调用wait的线程才会解除wait状态，可以去参与竞争同步资源锁；

- 异常捕获：sleep需要捕获或者抛出异常，而wait/notify/notifyAll则不需要；

### 1.4 Java线程和操作系统线程的关系

Java 线程状态是在操作系统线程状态的基础上进行的抽象和封装。Java 线程的运行最终还是要依赖操作系统的线程调度和执行机制。

Java线程模型简化了操作系统的线程模型。

Java中的线程和操作系统的线程并非一一对应，JVM可以将多个Java线程的任务分配给一个操作系统线程。

### 1.5 并行 并发

### 1.6 进程 线程 协程

## 2 Java内存模型（JMM）

JMM（Java Memory Model）主要聚焦于多线程环境下的内存访问规则，是对 JVM 内存管理的一种抽象和规范补充。

它涵盖的主题包括变量的可见性、指令重排、原子操作等，旨在解决由于多线程并发编程带来的一些问题。

### 2.1 happens-before原则

面向开发者而非编译器，happens-before在多线程程序的时间轴上建立了一个先后顺序的约束。

指令重排必须遵守这些规则。

- 程序顺序规则：代码顺序执行，前面的代码 happens-before后面的代码

- 管程锁定规则：加锁 happens-before 解锁 （monitorenter happens-before monitorexit）
- volatile变量规则：写happens-before读
- 线程启动规则：start方法happens-before其他任何操作
- 传递性规则：顾名思义

### 2.2 工作内存

JMM则规定，在线程共享的主内存之外，每个线程持有一块私有的工作内存。

主内存负责存储对象实例、静态变量等数据，而线程对变量的操作（如读取、赋值等）都在自己的工作内存中进行。

JMM 中的主内存概念可以对应到 JVM 中的堆、方法区等共享内存区域，线程的工作内存则可以看作是线程栈以及部分缓存机制（如 CPU 缓存）的抽象结合。

Java 内存模型定义了包括read、write、lock、unlock、load、store等8种同步操作，来保证工作内存和主内存的正确交互。

### 2.3 JMM和JVM运行时内存区域

简而言之，一个抽象，一个具体。

JMM针对的是多线程环境下，如何在主内存与工作内存之间安全地执行操作。它是一种规范，一个模型。

JVM运行时内存区域则是具体详细的内存划分，比如堆、栈、方法区等等。

JMM 定义的规则需要通过 JVM 来具体实现。JVM 在实现过程中会利用硬件的内存架构和自身的内存管理机制来满足 JMM 的要求。

## 3 volatile

volatile是Java对内存屏障的实现，保证变量的可见性和禁止指令重排序

### 3.1 可见性

可见性是指当一个线程修改了共享变量的值后，其他线程能够立即察觉到这个修改并获取到最新的值。

**破坏可见性**

- 缓存：计算机多级缓存
- 指令重排：多线程环境下，重排序可能会导致一个线程看到的共享变量的状态不符合预期

### 3.2 重排序

**引申**：CPU缓存一致性协议MESI，通过广播失效来保证多CPU的缓存一致性。同时为了避免阻塞带来性能问题，将缓存失效异步处理。

- 编译器指令重排：编译器层面的优化，对没有依赖关系的代码进行重排
- CPU指令重排：CPU层面的优化，提高并行度
- 内存系统重排：写缓冲区和失效队列异步处理缓存失效，带来指令执行顺序和写入内存顺序不一致的问题

### 3.3 内存屏障

本质是CPU指令，作用有两个

- 顺序性：禁止屏障两侧，即屏障这条CPU指令两侧的指令重排
- 一致性：强制刷新内存和失效其他CPU的缓存

三个指令

- 读屏障（Load）：确保在该屏障之后的读操作能够看到屏障之前的所有写操作的结果。
- 写屏障（Store）：保证在该屏障之前的写操作先于屏障之后的写操作执行，并且将屏障之前的写操作的结果刷新到主内存中。
- 全屏障（Full）：同时保证读写操作的可见性和顺序性

组合出四种内存屏障：StoreStore,LoadLoad,LoadStore,StoreLoad

StoreLoad最通用，屏障左边的写操作会被立即刷入主存，屏障右边的读操作会从主存读最新的值。从而保证了可见性。

### 3.4 volatile实现

对于被volatile修饰的变量

写操作之前：加StoreStore屏障，保证当前写操作一定是在之前的写操作生效的基础上进行的，保证两次写操作的顺序性。

写操作之后：加StoreLoad屏障，保证当前写操作产生的结果对之后的读操作可见。

读操作之前：加LoadLoad屏障，保证在当前读操作之前的读操作不会被重排到后面。

读操作之后：加LoadStore屏障，保证在读操作之后的写操作不会被重排到读操作之前。

### 3.5 volatile和原子性

volatile只作用于变量的单个读/写操作，对于复合操作如自增自减无能为力。

## 4 synchronized

### 4.1 Monitor锁对象

**Synchronized可以把任何一个非null对象作为"锁"**

作用方式不同时，Monitor对象也不同

- 同步代码块：锁住给定的对象
- 同步方法：锁对象实例this
- 同步静态方法：锁住class对象

### 4.2 同步原理

synchronized的同步依赖monitorenter和monitorexit两条指令实现，前者加锁，后者退出锁。

**两个指令的执行是JVM通过调用操作系统的互斥原语mutex来实现，被阻塞的线程会被挂起、等待重新调度**，会导致用户态和内核态两个态之间来回切换，对性能有较大影响。

### 4.3 MESA管程模型

管程的主要目的是将共享资源的管理和对这些资源的操作封装在一起，使得对共享资源的访问能够以一种安全、有序的方式进行。在管程内部，有一套规则来确保在同一时刻只有一个线程能够访问共享资源。

Java的同步synchronized和AQS均基于MESA管程模型实现。

**共享变量封装：**在 MESA 管程模型中，共享变量被定义在管程内部，外部线程无法直接访问这些变量，只能通过管程提供的接口方法来操作。对于synchronized，共享变量就是Monitor锁对象，对外提供wait、notify等方法操作Monitor对象。

**入口队列：**当多个线程试图进入管程时，会在管程的入口处形成一个队列，称为入口队列。入口队列的存在确保了线程按照一定的顺序（通常是先来先服务，但也可以根据具体实现有所不同）进入管程。在Java中，同时只有一个对象能获取锁，被阻塞的线程类似于入口队列机制，在Monitor对象之外等待。

**条件变量和等待队列：**用于让线程在某个条件不满足时等待，直到其他线程使这个条件满足并唤醒等待的线程。每个条件变量都与一个等待队列相关联，线程可以在这个等待队列中等待特定条件的满足。用Java代入这个模型，wait释放当前锁进入等待状态，这个状态类似于进入等待队列。

### 4.4 锁优化

#### 4.4.1 自适应自旋锁

**线程的阻塞和唤醒需要CPU从用户态转为核心态**，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，**对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的**。所以引入自旋锁，当一个线程尝试获取某个锁时，**如果该锁已被其他线程占用，就一直循环检测锁是否被释放**，而不是进入线程挂起或睡眠状态。

自旋必须有一个限度，无限自旋是对CPU资源的浪费。

引入自适应自旋次数：自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多，反之减少。

#### 4.4.2 锁消除

有些情况下，JVM检测到不可能存在共享数据竞争（逃逸分析），这是JVM会对这些同步锁进行锁消除。

#### 4.4.3 锁粗化

如果对锁的使用过于精细，可能会导致性能下降。锁粗化就是将多个连续的、对同一个锁的操作合并为一个范围更大的锁操作，从而减少获取和释放锁的次数，以提高性能。

场景：循环加锁，JVM会把锁提到循环外。

#### 4.4.4 锁膨胀

无锁->偏向锁->轻量级锁->重量级锁

#### 4.4.5 偏向锁

**在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得。**引入偏向锁，降低线程加锁的代价。偏向锁非常适合在单线程环境下或者在多线程环境中，一个对象的同步块主要被一个线程频繁访问，而其他线程很少访问的情况。

**加锁：**检查Java对象头中Mark Word中的偏向锁标志位，若无偏向锁则写入当前的线程id从而获得锁；若有则检查当前的偏向锁线程id，相等则直接获取锁，不等则膨胀为轻量级锁。

**解锁：**同步代码块执行结束释放；当其他线程来竞争时，JVM在Safe Point暂停当前持有偏向锁的线程，然后根据这个线程同步代码执行状态决定是释放锁到无锁状态还是膨胀到轻量级锁；

#### 4.4.6 轻量级锁

**加锁：**膨胀为轻量级锁之后，JVM会先在当前线程的**栈桢**中创建**锁记录空间**，并将对象头中的Mark Word复制到锁记录中，然后线程尝试将对象头中的Mark Word的数据**CAS**为**指向锁记录的指针**。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在两条或两条以上的线程竞争同一个锁，则轻量级锁会膨胀成重量级锁。

**解锁：**尝试把栈帧锁空间中存储的Mark Word通过CAS放回对象头，成功则回归无锁状态或者再次偏向；失败则代表锁已被其他线程持有，不做任何操作。

#### 4.4.7 重量级锁

依赖于操作系统Mutex Lock实现，涉及线程的阻塞和唤醒，以及操作系统的调度，开销最大。

避免了自旋对CPU资源的消耗，适用于多线程竞争非常激烈，并且线程持有锁的时间较长的场景。

## 5 CAS

CAS是一种乐观锁，将比较和赋值两个操作封装起来，在硬件层面保证原子性。

Java的CAS依赖unsafe包中提供的native方法实现。

### 5.1 CAS自旋

一种在多线程环境下使用 CAS（Compare - And - Swap）操作时的策略。当一个线程执行 CAS 操作尝试更新共享变量但失败时，它不会立即进入阻塞状态，而是会在一个循环中不断地再次尝试执行 CAS 操作，这个循环过程就被称为 CAS 自旋。

**优势**

- 快速响应共享变量的变化
- 快速响应共享变量的变化

**可能存在的问题**

- CPU资源消耗：自旋是CPU空转，次数过多是对CPU的浪费，需要一定的策略控制次数，类比synchronized悲观锁的自适应自旋。
- 无法保证公平性：可能会造成某些线程长时间自旋无法成功更新。

### 5.2 CAS在Java中应用

- 原子类（Atomic）的实现基础
- 无锁队列，例如Disruptor利用CAS写环形缓冲
- AQS中用CAS操作状态变量，以实现加锁和解锁，保证可重入

### 5.3 ABA问题

以一个链表为例，初始链表A->B->null，线程1期望将A和B交换，此时线程2先行一步移除元素B并在后面插入了C、D两个元素，链表变成A->C->D->null，B->null，然后线程1再进来CAS时发现链表头为A，CAS成功，于是链表变为B->null，这样C、D两个元素就消失了。

**解决办法：**CAS比较时同时比较版本号和时间戳

### 5.4 CAS和总线风暴

CAS 操作本质上是一种硬件级别的原子操作，在多处理器系统中，当多个处理器核心尝试对共享内存中的同一数据进行 CAS 操作时，需要通过系统总线来保证数据的一致性。CAS同时涉及总线读和写操作，高并发场景下，会影响总线的通信效率，导致系统响应变慢。

## 6 AQS

AQS 是一个用于构建锁和同步器的基础**框架**。它提供了一种实现阻塞式同步容器的通用机制，抽象出了同步状态的获取和释放操作，并且通过维护一个同步队列（FIFO 队列）来管理等待获取同步状态的线程。

### 6.1 AQS核心

- **同步状态state**：这是 AQS 的核心变量，通常是一个整型值，用于表示同步状态。例如，在`ReentrantLock`中，`state`可以表示锁是否被占用（0 表示未被占用，大于 0 表示被占用，且可以用于记录重入次数）；在`CountDownLatch`中，`state`表示还需要等待的事件数量。这个变量的具体含义和操作方式由 AQS 的子类根据不同的同步需求来定义。

- **同步队列（CLH 队列）**：AQS 内部维护的一个双向链表结构的队列，用于存放等待获取同步状态的线程。每个节点（Node）代表一个等待线程，节点中包含了线程引用、等待状态等信息。当线程尝试获取同步状态失败时，就会被封装成一个节点添加到同步队列的尾部，然后进入等待状态。这个队列的操作（如入队、出队、等待唤醒等）是 AQS 实现线程阻塞和唤醒机制的基础。

  **头节点一定代表当前持有锁的线程。**

- **线程等待状态waitStatus：**CLH队列中节点（等待的线程）的等待状态。可能的取值有五种。
  - **初始值（0）：**节点初始入队时的默认值，无意义
  - **已取消 CANCELLED（1）：**线程已超时/中断，即不再等待同步状态
  - **后继待唤醒 SIGNAL（-1）：**当前节点的线程退出同步状态时，唤醒下一个节点。新节点入队时，将前一个节点置为SIGNAL。
  - **条件等待 CONDITION（-2）：**结合Condition说明。
  - **传播唤醒 PROPAGATE（-3）：**结合Semaphore说明。


### 6.2 AQS模板方法

AQS提供了几个非抽象的模板方法，子类可以按需实现。

- **tryAcquire：**独占式获取同步状态。
- **tryRelease：**独占式释放同步状态。
- **tryAcquireShared：**共享方式尝试获取资源。
- **tryReleaseShared：**共享方式尝试释放资源。

### 6.3 AQS和管程

AQS和synchronized一样，都可以视作Java对管程模型的实现。

ReentrantLock和synchronized的诸多相似之处都可以归结到管程模型上。

AQS的很多概念可以在管程模型中找到对应

- state变量 - 管程互斥
- CLH队列 - 入口队列
- ConditionObject - 条件等待

## 7 ReentrantLock

### 7.1 可重入

ReentrantLock实现可重入：通过AQS的state记录重入次数，当前线程每次获取锁，通过CAS使state+1；释放锁时-1，直到state清零，锁才真正释放。

可重入的意义：避免同一个线程尝试多次获取同一个锁时发生死锁

### 7.2 公平锁



### 7.3 和synchronized比较

## 8 Condition

## 9 ReentrantReadWriteLock

## 10 LockSupport

LockSupport提供了基本的线程同步原语，底层是一系列native方法。

主要有park和unpark两个方法。

### 10.1 park

### 10.2 unpark

## 11 Collection

## 12 ThreadLocal

## 13 ThreadPool

## 14 unsafe

## 15 ForkJoinPool





[☆啃碎并发（七）：深入分析Synchronized原理](https://www.jianshu.com/p/e62fa839aa41)

[ABA问题例子](https://blog.csdn.net/WSYW126/article/details/53979918)

